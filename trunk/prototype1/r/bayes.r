# PURPOSE : To estimate the input-output mapping with inputs x
#           and outputs y generated by the following nonlinear,
#           nonstationary state space model:
#           x(t+1) = 0.5x(t) + [25x(t)]/[(1+x(t))^(2)]
#                    + 8cos(1.2t) + process noise
#           y(t) =  x(t)^(2) / 20  + 6 squareWave(0.05(t-1)) + 3
#                   + time varying measurement noise
#           using a multi-layer perceptron (MLP) and both the EKF and
#           the hybrid importance-samping resampling (SIR) algorithm.

# AUTHOR  : Nando de Freitas - Thanks for the acknowledgement :-)
# DATE    : 08-09-98
# TRANSLATED TO R By : Alessandro Bonazzi
# DATE    : 10-08-07

library(RMySQL)
mycon <- dbConnect(MySQL(), user='testuser', dbname="bayesfortest", host="localhost", password='test')
query_1 <- dbSendQuery(mycon, "SELECT a.id, c.name, avg(a.count) as num, date(a.scantime) as data
                             FROM words a, int_words c, pages b
                             WHERE a.id = c.id
                               AND a.page_id = b.id
                               AND a.id = 1
                             GROUP BY a.id, c.name, date(a.scantime);")
china <- fetch(query_1, n = -1)

query_2 <- dbSendQuery(mycon, "SELECT a.id, c.name, avg(a.count) as num, date(a.scantime) as data
                             FROM words a, int_words c, pages b
                             WHERE a.id = c.id
                               AND a.page_id = b.id
                               AND a.id = 2
                             GROUP BY a.id, c.name, date(a.scantime);")
india <- fetch(query_2, n = -1)

source("hybridsir.r")
source("reader.r")

N= length(china[,3])
x<-y<-array(0,dim=c(N,1))

y[,1]=india[,3]
x[,1]=china[,3]
# INITIALISATION AND PARAMETERS:
# =============================

t = 1:1:N              # Time.
actualR = 2            # Measurement noise variance.
actualQ = 1e-2         # Process noise variance.
numSamples=1000          # Number of Monte Carlo samples per time step.
s1=10                  # Neurons in the hidden layer.
s2=1                   # Neurons in the output layer - only one in this implementation.
Q = 10               # Process noise variance.
R = 2                  # Measurement noise variance.
initVar1= 10           # Variance of prior for weights in the hidden layer.
initVar2= 10           # Variance of prior for weights in the output layer.
KalmanR = 1            # Kalman filter measurement noise covariance hyperparameter;
KalmanQ = 1        # Kalman filter process noise covariance hyperparameter;
KalmanP = 1            # Kalman filter initial weights covariance hyperparameter;


# ======================================
# PERFORM SEQUENTIAL MONTE CARLO FILTERING TO TRAIN MLP:
# =====================================================

hyb = hybridsir(x,y,s1,s2,numSamples,Q,initVar1,
           initVar2,R,KalmanR,KalmanQ,KalmanP,N)

png(file="figure/prediction.png")
plot(ts(x),type="o",col=2,ylim=c(-10, 50),lwd=2)
lines(ts(y),type="b",col=3,lwd=2)
for ( i in 1: numSamples ) {
lines(ts(hyb$m[i,]),type="b",lwd=1)
}
lines(ts(x),type="o",col=2,ylim=c(-10, 50),lwd=2)
lines(ts(y),type="b",col=3,lwd=2)
title("Predictor (RED), Forecast ( Black ), Verification ( Green )")
dev.off

png(file="figure/hist.png")
hist(hyb$m[,N],100, main="Histogram of forecast at last time series pillar")
# FIXME: add observed value line in graph
dev.off()
